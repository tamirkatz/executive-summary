from __future__ import annotations

import asyncio
import os
from datetime import datetime
from typing import Any, Dict, List, Optional

from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
from tavily import AsyncTavilyClient

from ..agents.base_agent import BaseAgent

# ---------------------------------------------------------------------------
# Pydantic Schemas (LLM structured outputs)
# ---------------------------------------------------------------------------

class SearchQueries(BaseModel):
    """Exactly 30 search queries generated by the LLM."""

    queries: List[str] = Field(
        description="List of 30 competitor search queries", min_length=30, max_length=30
    )


class CompetitorNames(BaseModel):
    """Raw list of competitor names extracted by the LLM."""

    competitors: List[str] = Field(
        description="List of competitor company names", max_length=100
    )


# ---------------------------------------------------------------------------
# Agent Definition
# ---------------------------------------------------------------------------


class CompetitorSearchAgent(BaseAgent):
    """Agent responsible for generating search queries, executing them via Tavily, and
    extracting a de-duplicated list of competitor names.
    """

    def __init__(self, llm_model: str = "gpt-4o", *, rate_limit: int = 2):
        super().__init__(agent_type="competitor_search_agent")

        # Environment validation ------------------------------------------------------
        if not os.getenv("TAVILY_API_KEY"):
            raise ValueError("TAVILY_API_KEY is not configured")
        if not os.getenv("OPENAI_API_KEY"):
            raise ValueError("OPENAI_API_KEY is not configured")

        self.llm_model = llm_model
        self.temperature = 0.3
        self.rate_limit = rate_limit

        self.llm = ChatOpenAI(
            model=self.llm_model,
            temperature=self.temperature,
            api_key=os.getenv("OPENAI_API_KEY"),
        )
        self.tavily = AsyncTavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
        self.sem = asyncio.Semaphore(self.rate_limit)

    # ---------------------------------------------------------------------
    # Public API
    # ---------------------------------------------------------------------

    async def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Main entry-point for the agent.

        Expected state keys (read):
            • company – Company name.
            • profile – Dict that may include `description` & `core_products`.
            • websocket_manager / job_id – For UI notifications.

        Side-effects (write):
            • state["competitor_search"] – Metadata about the search phase.
            • state["candidate_competitors"] – List[str] of competitor names.
        """

        self.log_agent_start(state)
        company = state.get("company", "Unknown Company")
        websocket_manager, job_id = self.get_websocket_info(state)

        # ------------------------------------------------------------------
        # Phase 1 – Generate search queries
        # ------------------------------------------------------------------
        await self.send_status_update(
            websocket_manager,
            job_id,
            status="processing",
            message=f"🔍 Generating search queries for {company}",
            result={"step": "Competitor Search", "substep": "query_generation"},
        )

        profile = state.get("profile", {})
        company_description = profile.get("description", "")
        core_products = profile.get("core_products", [])

        search_queries = await self._generate_search_queries(
            company, company_description, core_products
        )

        # ------------------------------------------------------------------
        # Phase 2 – Run Tavily searches concurrently
        # ------------------------------------------------------------------
        await self.send_status_update(
            websocket_manager,
            job_id,
            status="processing",
            message=f"🌐 Running {len(search_queries)} Tavily searches",
            result={"step": "Competitor Search", "substep": "execute_searches"},
        )

        combined_results = await self._execute_searches_and_combine(search_queries)

        # ------------------------------------------------------------------
        # Phase 3 – Extract competitor names
        # ------------------------------------------------------------------
        await self.send_status_update(
            websocket_manager,
            job_id,
            status="processing",
            message="🧮 Extracting competitor names from results",
            result={"step": "Competitor Search", "substep": "name_extraction"},
        )

        competitor_names = await self._extract_competitor_names(
            company, company_description, core_products, combined_results
        )

        # Persist results back to state ----------------------------------------------
        state["competitor_search"] = {
            "general_queries": search_queries,
            "initial_competitors_found": len(competitor_names),
            "combined_results_meta": {
                "total_queries": combined_results.get("total_queries"),
                "successful_searches": combined_results.get("successful_searches"),
            },
        }
        state["candidate_competitors"] = competitor_names

        await self.send_status_update(
            websocket_manager,
            job_id,
            status="search_complete",
            message=f"✅ Found {len(competitor_names)} raw competitor candidates",
            result={
                "step": "Competitor Search",
                "substep": "complete",
                "candidate_count": len(competitor_names),
            },
        )

        self.log_agent_complete(state)
        return state

    # ---------------------------------------------------------------------
    # Internal helpers
    # ---------------------------------------------------------------------

    async def _generate_search_queries(
        self, company: str, description: str, core_products: List[str]
    ) -> List[str]:
        """Prompt the LLM for exactly 30 search queries."""

        core_products_text = ", ".join(core_products) if core_products else "N/A"
        current_year = datetime.now().year
        prev_year = current_year - 1

        prompt = f"""You are a competitive intelligence analyst. Generate exactly 30 search queries to find competitors for the following company.

Company: {company}
Description: {description}
Core Products: {core_products_text}

Generate search queries that will help discover the company's main competitors. IMPORTANT: Each query must include either '{current_year}' or '{prev_year}' or words like 'recent', 'latest' to ensure only the most up-to-date and relevant competitors are found.

Return exactly 30 queries."""

        llm_with_schema = self.llm.with_structured_output(SearchQueries)
        response = await llm_with_schema.ainvoke(prompt)
        self.logger.info("Search queries generated", extra={"queries": response.queries})
        return response.queries

    async def _execute_searches_and_combine(self, queries: List[str]) -> Dict[str, Any]:
        """Fire off Tavily searches concurrently and aggregate their responses."""

        async def _single_search(query: str) -> Dict[str, Any]:
            async with self.sem:
                max_attempts = 3
                delay = 5  # seconds
                attempt = 0
                while attempt < max_attempts:
                    try:
                        result = await self.tavily.search(
                            query=query,
                            max_results=5,
                            include_answer=True,
                            include_raw_content=False,
                        )
                        return {
                            "query": query,
                            "results": result.get("results", []),
                            "answer": result.get("answer", ""),
                        }
                    except Exception as e:
                        err_msg = str(e).lower()
                        # Detect Tavily rate-limit / excessive requests error
                        if "excessive requests" in err_msg or "rate" in err_msg:
                            attempt += 1
                            if attempt < max_attempts:
                                wait_time = delay * attempt
                                self.logger.warning(
                                    f"Rate limit hit on Tavily search (attempt {attempt}/{max_attempts}) – retrying in {wait_time}s"
                                )
                                await asyncio.sleep(wait_time)
                                continue
                        # For other errors or after retries exhausted, return error payload
                        self.logger.warning(f"Search failed for query '{query}': {e}")
                        return {"query": query, "results": [], "answer": "", "error": str(e)}
                # Should not reach here, but safeguard return
                return {"query": query, "results": [], "answer": "", "error": "max_retries_exceeded"}

        tasks = [_single_search(q) for q in queries]
        search_results = await asyncio.gather(*tasks)

        # Normalise structure ----------------------------------------------------------
        combined: Dict[str, Any] = {
            "total_queries": len(queries),
            "successful_searches": len([r for r in search_results if not r.get("error")]),
            "all_search_results": search_results,
            "all_content": [],
            "all_answers": [],
        }

        for result in search_results:
            if result.get("error"):
                continue

            if result.get("answer"):
                combined["all_answers"].append(
                    {"query": result["query"], "answer": result["answer"]}
                )

            for item in result.get("results", []):
                combined["all_content"].append(
                    {
                        "query": result["query"],
                        "title": item.get("title", ""),
                        "content": item.get("content", ""),
                        "url": item.get("url", ""),
                    }
                )

        return combined

    async def _extract_competitor_names(
        self,
        company: str,
        description: str,
        core_products: List[str],
        combined_results: Dict[str, Any],
    ) -> List[str]:
        """Use an LLM pass to pull out potential competitor names from the Tavily corpus."""

        # --- Condense Tavily data for the prompt -------------------------------------
        content_snippets: List[str] = []
        for item in combined_results.get("all_content", []):
            snippet = (
                f"Query: {item['query']}\nTitle: {item['title']}\nContent: {item['content'][:500]}\n---"
            )
            content_snippets.append(snippet)

        answer_snippets: List[str] = []
        for answer_item in combined_results.get("all_answers", []):
            snippet = f"Query: {answer_item['query']}\nAnswer: {answer_item['answer']}\n---"
            answer_snippets.append(snippet)

        all_content = "\n".join(content_snippets)[:15000]
        all_answers = "\n".join(answer_snippets)[:5000]

        core_products_text = ", ".join(core_products) if core_products else "N/A"

        prompt = f"""You are a competitive intelligence analyst. Extract the names of competitor companies from the search results below.

TARGET COMPANY: {company}
DESCRIPTION: {description}
CORE PRODUCTS: {core_products_text}

SEARCH RESULTS:
{all_content}

SEARCH ANSWERS:
{all_answers}

Instructions:
1. Identify companies that could be competitors to the target company
2. Focus on companies that offer similar products, services, or solutions
3. Include direct competitors, indirect competitors, and alternative solutions
4. Return only clean company names (no descriptions or additional text)
5. Remove duplicates and ensure names are properly formatted
6. Exclude the target company itself
7. Exclude generic terms, technologies, or non-company entities
8. Focus on actual company names that can be researched further

Return a list of up to 100 competitor company names."""

        llm_with_schema = self.llm.with_structured_output(CompetitorNames)
        response = await llm_with_schema.ainvoke(prompt)

        # Post-process & de-duplicate --------------------------------------------------
        competitors: List[str] = []
        seen: set[str] = set()
        for name in response.competitors:
            cleaned = name.strip()
            if not cleaned or len(cleaned) > 100 or cleaned.lower() == company.lower():
                continue
            if cleaned.lower() not in seen:
                seen.add(cleaned.lower())
                competitors.append(cleaned)

        return competitors 